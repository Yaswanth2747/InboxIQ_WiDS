{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38012a9",
   "metadata": {},
   "source": [
    "# InboxIQ: Intelligent Email Filtering with Machine Learning  \n",
    "### Winter Data Science (WiDS) Program  \n",
    "\n",
    "Welcome to the InboxIQ project! This notebook is designed to guide you through the process of building an intelligent email filtering system to classify emails as ham or spam using a Recurrent Neural Network (RNN).  \n",
    "\n",
    "## Objectives  \n",
    "This project aims to:  \n",
    "1. Provide hands-on experience with email classification using RNNs.  \n",
    "2. Help you understand fundamental concepts such as data preprocessing, tokenization, padding, label encoding, and model evaluation.  \n",
    "3. Emphasize the importance of key techniques like early stopping, activation functions, and proper data splitting for training and validation.  \n",
    "\n",
    "## Submission Requirements  \n",
    "- **Deadline**: The completed project (code + report) is due on **January 7, 11:59 PM**.  \n",
    "- **What to Submit**: Your submission must include:  \n",
    "  - A fully functional Python script or Jupyter Notebook for the email classification system.  \n",
    "  - A detailed report explaining your implementation and highlighting key concepts.  \n",
    "\n",
    "## Guidelines  \n",
    "- The outlined code provided in this notebook is kept intentionally simple to help you focus on understanding the core concepts rather than dealing with excessive complexity.  \n",
    "- **Flexibility**:  \n",
    "  - You can use the provided outline as is.  \n",
    "  - Modify the outlined code as needed.  \n",
    "  - Alternatively, feel free to write your own implementation from scratch.  \n",
    "\n",
    "## Key Expectations  \n",
    "- **Conceptual Understanding**: Your report should demonstrate a thorough understanding of:  \n",
    "  - Data preprocessing steps (e.g., tokenization, padding, label encoding).  \n",
    "  - The role of activation functions and loss metrics.  \n",
    "  - How early stopping helps prevent overfitting.  \n",
    "  - The purpose and implementation of each line of code.  \n",
    "- **Exhaustive Submission**: Your submission (code + report) will serve as the exhaustive assessment for certification. Report is much important for evaluation.  \n",
    "\n",
    "Take your time to experiment, learn, and reflect on the process. This project is not just about completing the task; itâ€™s about building a solid foundation in machine learning concepts applied to real-world problems.  \n",
    "\n",
    "Submission Link : https://forms.gle/VA3ArTGhXcHee4nY7\n",
    "\n",
    "Good luck, and happy coding!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ad217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries, you're free to add any extra libraries if you want\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba723d51",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"________________\"  # Provide the correct path to the dataset.\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f20132",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9142d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with the data, like see how much biased is the dataset provided to you, print it's starting 10 rows, etc.\n",
    "________________\n",
    "________________\n",
    "________________\n",
    "________________\n",
    "________________\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bd523",
   "metadata": {},
   "source": [
    "Preprocess the text (tokenization, cleaning, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36330fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataset has a column 'text' for email content and 'label' for spam/ham, it would be appreciated if you do it by extra lines of code using Pandas.\n",
    "texts = ______________  # Fill\n",
    "labels = ______________\n",
    "\n",
    "# Convert labels to numerical format (e.g., 0 for ham, 1 for spam), check the CSV file if this step is actually necessary?\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e690d",
   "metadata": {},
   "source": [
    "Tokenizing and pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4feba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000  # Maximum vocabulary size\n",
    "max_len = 100     # Maximum sequence length\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='_____') # Fill with 'pre' or 'post', reason should be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a2932",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a809916",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(________, labels, test_size=_______, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda5071",
   "metadata": {},
   "source": [
    "Building the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
    "    SimpleRNN(64, activation='____'), # Fill in with appropriate activation functions, a reasoning has to be provided in the report.\n",
    "    Dense(1, activation='_____')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8ddbd",
   "metadata": {},
   "source": [
    "Training the model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200960a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping configuration\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=____,  # Fill in number of epochs\n",
    "    validation_data=(____, ____),  # Fill in validation data\n",
    "    callbacks=[callback],\n",
    "    batch_size=____  # Fill in batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96ab76",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(____, ____) # Fill here\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca97c5d",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e44b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model by entering a few sample inputs and check your wonderfull model for yourself.\n",
    "sample_texts = [\"___________________________\"] # A message like \"Congratulations! you've won a Nobel Pri....\"\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
    "sample_padded = pad_sequences(________________, maxlen=max_len, padding='post') # Fill in here\n",
    "predictions = model.predict(______________) # Fill in here\n",
    "\n",
    "for text, pred in zip(sample_texts, predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction (Spam Probability): {pred[0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
